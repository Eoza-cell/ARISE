
const fs = require('fs').promises;
const path = require('path');

class HuggingFaceClient {
    constructor() {
        this.apiKey = process.env.HF_TOKEN;
        this.isAvailable = false;
        this.baseURL = 'https://router.huggingface.co/fal-ai/fal-ai/ltxv-13b-098-distilled/image-to-video';
        
        this.initializeClient();
    }

    async initializeClient() {
        try {
            if (!this.apiKey) {
                console.log('‚ö†Ô∏è HF_TOKEN non trouv√©e - g√©n√©ration de vid√©os Hugging Face d√©sactiv√©e');
                return;
            }

            this.isAvailable = true;
            console.log('‚úÖ Client Hugging Face initialis√© avec succ√®s (ltxv-13b-098-distilled)');

        } catch (error) {
            console.error('‚ùå Erreur lors de l\'initialisation du client Hugging Face:', error.message);
            this.isAvailable = false;
        }
    }

    hasValidClient() {
        return this.isAvailable && this.apiKey;
    }

    async generateVideoFromText(prompt, outputPath, options = {}) {
        try {
            if (!this.hasValidClient()) {
                throw new Error('Client Hugging Face non disponible - v√©rifiez HF_TOKEN');
            }

            console.log(`ü§ó G√©n√©ration vid√©o Hugging Face avec prompt: "${prompt.substring(0, 100)}..."`);

            // Utiliser l'image du personnage si disponible
            let characterImage = null;
            if (options.characterImagePath) {
                try {
                    characterImage = await fs.readFile(options.characterImagePath);
                    console.log(`üì∏ Image du personnage charg√©e: ${options.characterImagePath}`);
                } catch (error) {
                    console.log(`‚ö†Ô∏è Impossible de charger l'image: ${options.characterImagePath}`);
                }
            }

            // Si pas d'image de personnage, essayer le mod√®le de fallback
            if (!characterImage) {
                console.log('‚ö†Ô∏è Pas d\'image de personnage disponible - utilisation du mod√®le fallback text-to-video');
                return await this.generateVideoWithFallbackModel(prompt, outputPath, options);
            }

            const optimizedPrompt = this.optimizePromptForImageToVideo(prompt);
            
            console.log(`üé¨ Utilisation du mod√®le ltxv-13b-098-distilled pour g√©n√©ration vid√©o image-to-video...`);

            // Utiliser le nouveau mod√®le image-to-video
            const response = await fetch(`${this.baseURL}?_subdomain=queue`, {
                headers: {
                    'Authorization': `Bearer ${this.apiKey}`,
                    'Content-Type': 'application/json',
                },
                method: 'POST',
                body: JSON.stringify({
                    image_url: `data:image/png;base64,${characterImage.toString('base64')}`,
                    prompt: optimizedPrompt,
                    duration: options.duration || 5,
                    fps: options.fps || 24,
                    width: options.width || 1024,
                    height: options.height || 768
                })
            });

            if (!response.ok) {
                throw new Error(`Erreur API HuggingFace: ${response.status} ${response.statusText}`);
            }

            const result = await response.json();
            console.log(`üì• R√©ponse re√ßue, traitement de la vid√©o...`);

            // G√©rer la r√©ponse selon le format retourn√©
            let videoBuffer;
            if (result.video_url) {
                // T√©l√©charger la vid√©o depuis l'URL
                const videoResponse = await fetch(result.video_url);
                if (!videoResponse.ok) {
                    throw new Error(`Erreur t√©l√©chargement vid√©o: ${videoResponse.status}`);
                }
                const arrayBuffer = await videoResponse.arrayBuffer();
                videoBuffer = Buffer.from(arrayBuffer);
            } else if (result.video) {
                // Vid√©o encod√©e en base64
                videoBuffer = Buffer.from(result.video, 'base64');
            } else {
                throw new Error('Format de r√©ponse vid√©o inattendu');
            }
            
            // Cr√©er le dossier de sortie si n√©cessaire
            const outputDir = path.dirname(outputPath);
            await fs.mkdir(outputDir, { recursive: true });

            await fs.writeFile(outputPath, videoBuffer);
            console.log(`‚úÖ Vid√©o Hugging Face g√©n√©r√©e avec ltxv-13b-098-distilled: ${outputPath} (${videoBuffer.length} bytes)`);
            
            return {
                success: true,
                videoPath: outputPath,
                duration: options.duration || 5,
                provider: 'huggingface',
                model: 'ltxv-13b-098-distilled',
                fileSize: videoBuffer.length
            };

        } catch (error) {
            console.error('‚ùå Erreur g√©n√©ration vid√©o Hugging Face:', error.message);
            throw new Error(`G√©n√©ration vid√©o √©chou√©e: ${error.message}`);
        }
    }

    async generateVideoWithFallbackModel(prompt, outputPath, options = {}) {
        try {
            console.log(`üîÑ Utilisation du mod√®le de fallback text-to-video...`);

            // Fallback vers un mod√®le text-to-video classique si image-to-video √©choue
            const response = await fetch('https://api-inference.huggingface.co/models/damo-vilab/text-to-video-ms-1.7b', {
                headers: {
                    'Authorization': `Bearer ${this.apiKey}`,
                    'Content-Type': 'application/json',
                },
                method: 'POST',
                body: JSON.stringify({
                    inputs: this.optimizePromptForImageToVideo(prompt),
                    parameters: {
                        num_frames: options.num_frames || 16,
                        fps: options.fps || 8,
                        width: options.width || 256,
                        height: options.height || 256
                    }
                })
            });

            if (!response.ok) {
                throw new Error(`Erreur API fallback: ${response.status}`);
            }

            const videoBuffer = Buffer.from(await response.arrayBuffer());
            
            const outputDir = path.dirname(outputPath);
            await fs.mkdir(outputDir, { recursive: true });

            await fs.writeFile(outputPath, videoBuffer);
            console.log(`‚úÖ Vid√©o Hugging Face g√©n√©r√©e avec mod√®le de fallback: ${outputPath}`);
            
            return {
                success: true,
                videoPath: outputPath,
                duration: options.duration || 5,
                provider: 'huggingface',
                model: 'damo-vilab/text-to-video-ms-1.7b',
                fileSize: videoBuffer.length
            };

        } catch (error) {
            console.error('‚ùå Erreur mod√®le de fallback:', error.message);
            throw error;
        }
    }

    optimizePromptForImageToVideo(prompt) {
        // Optimiser le prompt sp√©cifiquement pour image-to-video
        let optimized = prompt
            .replace(/['"]/g, '') // Supprimer les guillemets
            .replace(/\s+/g, ' ') // Normaliser les espaces
            .trim();

        // Ajouter des am√©liorations pour l'image-to-video
        const improvements = [
            'smooth movement',
            'natural motion',
            'fluid animation',
            'realistic movement',
            'cinematic quality'
        ];

        // Ajouter les am√©liorations si pas d√©j√† pr√©sentes
        improvements.forEach(improvement => {
            if (!optimized.toLowerCase().includes(improvement.toLowerCase())) {
                optimized += `, ${improvement}`;
            }
        });

        // Limiter la longueur pour le mod√®le
        if (optimized.length > 200) {
            optimized = optimized.substring(0, 197) + '...';
        }

        console.log(`üéØ Prompt optimis√© pour image-to-video: "${optimized}"`);
        return optimized;
    }

    // M√©thodes RPG sp√©cifiques avec support d'image
    async generateCombatVideo(action, character, outputPath) {
        const prompt = `${character.name} in medieval fantasy combat, ${action}, epic battle scene, dynamic movement, armor and weapons, dramatic lighting, action sequence`;
        
        return await this.generateVideoFromText(prompt, outputPath, {
            duration: 4,
            characterImagePath: character.imagePath || null
        });
    }

    async generateCharacterActionVideo(action, character, location, outputPath) {
        const prompt = `${character.name} performing ${action} in ${location}, medieval fantasy setting, character in motion, atmospheric environment, cinematic camera angle`;
        
        return await this.generateVideoFromText(prompt, outputPath, {
            duration: 5,
            characterImagePath: character.imagePath || null
        });
    }

    async generateLocationVideo(location, character, outputPath) {
        const prompt = `Fantasy location: ${location}, ${character.name} exploring the area, epic landscape, atmospheric lighting, cinematic camera movement, medieval fantasy world`;
        
        return await this.generateVideoFromText(prompt, outputPath, {
            duration: 6,
            characterImagePath: character.imagePath || null
        });
    }

    async generateMagicSpellVideo(spellName, character, outputPath) {
        const prompt = `${character.name} casting ${spellName} magic spell, mystical energy effects, glowing magical aura, fantasy spellcasting, dynamic magical particles, epic scene`;
        
        return await this.generateVideoFromText(prompt, outputPath, {
            duration: 4,
            characterImagePath: character.imagePath || null
        });
    }

    // Nouvelle m√©thode pour g√©n√©rer une vid√©o avec une image personnalis√©e
    async generateVideoFromImage(imagePath, prompt, outputPath, options = {}) {
        try {
            console.log(`üé¨ G√©n√©ration vid√©o depuis image: ${imagePath}`);
            
            return await this.generateVideoFromText(prompt, outputPath, {
                ...options,
                characterImagePath: imagePath
            });
        } catch (error) {
            console.error('‚ùå Erreur g√©n√©ration vid√©o depuis image:', error);
            throw error;
        }
    }
}

module.exports = HuggingFaceClient;
