
const fs = require('fs').promises;
const path = require('path');

class HuggingFaceClient {
    constructor() {
        this.apiKey = process.env.HF_TOKEN;
        this.isAvailable = false;
        this.baseURL = 'https://router.huggingface.co/fal-ai/fal-ai/ltxv-13b-098-distilled/image-to-video';
        
        this.initializeClient();
    }

    async initializeClient() {
        try {
            if (!this.apiKey) {
                console.log('‚ö†Ô∏è HF_TOKEN non trouv√©e - g√©n√©ration de vid√©os Hugging Face d√©sactiv√©e');
                return;
            }

            this.isAvailable = true;
            console.log('‚úÖ Client Hugging Face initialis√© avec succ√®s (ltxv-13b-098-distilled)');

        } catch (error) {
            console.error('‚ùå Erreur lors de l\'initialisation du client Hugging Face:', error.message);
            this.isAvailable = false;
        }
    }

    hasValidClient() {
        return this.isAvailable && this.apiKey;
    }

    async generateVideoFromText(prompt, outputPath, options = {}) {
        try {
            if (!this.hasValidClient()) {
                console.log('‚ö†Ô∏è Client HuggingFace non disponible - HF_TOKEN manquante');
                return null;
            }

            console.log(`ü§ó G√©n√©ration vid√©o Hugging Face avec prompt: "${prompt.substring(0, 100)}..."`);

            // Utiliser l'image du personnage si disponible
            let characterImageBase64 = null;
            if (options.characterImagePath) {
                try {
                    const characterImage = await fs.readFile(options.characterImagePath);
                    characterImageBase64 = characterImage.toString('base64');
                    console.log(`üì∏ Image du personnage charg√©e: ${options.characterImagePath}`);
                } catch (error) {
                    console.log(`‚ö†Ô∏è Impossible de charger l'image: ${options.characterImagePath}`);
                }
            }

            const optimizedPrompt = this.optimizePromptForImageToVideo(prompt);
            
            // Pr√©parer les donn√©es de la requ√™te
            const requestData = {
                prompt: optimizedPrompt,
                duration: Math.min(options.duration || 3, 5), // Max 5 secondes
                fps: Math.min(options.fps || 8, 12), // Max 12 FPS
                width: Math.min(options.width || 256, 512), // Max 512px
                height: Math.min(options.height || 256, 512) // Max 512px
            };

            // Ajouter l'image si disponible
            if (characterImageBase64) {
                requestData.image = `data:image/png;base64,${characterImageBase64}`;
                console.log(`üé¨ Mode image-to-video avec ltxv-13b-098-distilled...`);
            } else {
                console.log(`üé¨ Mode text-to-video avec mod√®le de fallback...`);
            }

            // Essayer d'abord avec l'API Inference
            try {
                const apiUrl = characterImageBase64 ? 
                    'https://api-inference.huggingface.co/models/lightricks/LTX-Video' :
                    'https://api-inference.huggingface.co/models/damo-vilab/text-to-video-ms-1.7b';

                console.log(`üì§ Requ√™te vers: ${apiUrl}`);

                const response = await fetch(apiUrl, {
                    headers: {
                        'Authorization': `Bearer ${this.apiKey}`,
                        'Content-Type': 'application/json',
                    },
                    method: 'POST',
                    body: JSON.stringify(requestData),
                    timeout: 60000
                });

                if (!response.ok) {
                    throw new Error(`API HuggingFace: ${response.status} ${response.statusText}`);
                }

                const contentType = response.headers.get('content-type');
                console.log(`üì• Type de contenu: ${contentType}`);

                let videoBuffer;
                if (contentType && contentType.includes('video/')) {
                    // R√©ponse directe en vid√©o
                    const arrayBuffer = await response.arrayBuffer();
                    videoBuffer = Buffer.from(arrayBuffer);
                } else {
                    // R√©ponse JSON avec URL ou base64
                    const result = await response.json();
                    console.log(`üì• R√©ponse JSON re√ßue`);

                    if (result.video_url) {
                        // T√©l√©charger depuis l'URL
                        const videoResponse = await fetch(result.video_url, { timeout: 30000 });
                        if (!videoResponse.ok) {
                            throw new Error(`Erreur t√©l√©chargement: ${videoResponse.status}`);
                        }
                        const arrayBuffer = await videoResponse.arrayBuffer();
                        videoBuffer = Buffer.from(arrayBuffer);
                    } else if (result.video) {
                        // D√©coder base64
                        videoBuffer = Buffer.from(result.video, 'base64');
                    } else {
                        throw new Error('Format de r√©ponse inattendu');
                    }
                }
                
                // V√©rifier que c'est bien une vid√©o
                if (!videoBuffer || videoBuffer.length < 1000) {
                    throw new Error('Vid√©o g√©n√©r√©e trop petite ou invalide');
                }

                // Cr√©er le dossier et sauvegarder
                const outputDir = path.dirname(outputPath);
                await fs.mkdir(outputDir, { recursive: true });
                await fs.writeFile(outputPath, videoBuffer);
                
                console.log(`‚úÖ Vid√©o HuggingFace g√©n√©r√©e: ${outputPath} (${videoBuffer.length} bytes)`);
                
                return outputPath;

            } catch (apiError) {
                console.log(`‚ö†Ô∏è Erreur API principale: ${apiError.message}`);
                
                // Fallback vers mod√®le simple
                return await this.generateVideoWithSimpleFallback(prompt, outputPath, options);
            }

        } catch (error) {
            console.error('‚ùå Erreur g√©n√©ration vid√©o HuggingFace:', error.message);
            return null; // Retourner null au lieu de throw pour √©viter de casser le bot
        }
    }

    async generateVideoWithSimpleFallback(prompt, outputPath, options = {}) {
        try {
            console.log(`üîÑ Fallback vers mod√®le simple text-to-video...`);

            // Utiliser un mod√®le plus simple et fiable
            const response = await fetch('https://api-inference.huggingface.co/models/ali-vilab/text-to-video-ms-1.7b', {
                headers: {
                    'Authorization': `Bearer ${this.apiKey}`,
                    'Content-Type': 'application/json',
                },
                method: 'POST',
                body: JSON.stringify({
                    inputs: this.optimizePromptForImageToVideo(prompt),
                    parameters: {
                        num_inference_steps: 20, // R√©duit pour plus de vitesse
                        guidance_scale: 7.5,
                        width: 256,
                        height: 256,
                        num_frames: 8 // Tr√®s court
                    }
                }),
                timeout: 45000
            });

            if (!response.ok) {
                throw new Error(`Erreur mod√®le fallback: ${response.status}`);
            }

            const videoBuffer = Buffer.from(await response.arrayBuffer());
            
            if (videoBuffer.length < 500) {
                throw new Error('Vid√©o fallback trop petite');
            }

            const outputDir = path.dirname(outputPath);
            await fs.mkdir(outputDir, { recursive: true });
            await fs.writeFile(outputPath, videoBuffer);
            
            console.log(`‚úÖ Vid√©o fallback g√©n√©r√©e: ${outputPath} (${videoBuffer.length} bytes)`);
            return outputPath;

        } catch (error) {
            console.log('‚ùå √âchec du fallback vid√©o:', error.message);
            return null;
        }
    }

    async generateVideoWithFallbackModel(prompt, outputPath, options = {}) {
        try {
            console.log(`üîÑ Utilisation du mod√®le de fallback text-to-video...`);

            // Fallback vers un mod√®le text-to-video classique si image-to-video √©choue
            const response = await fetch('https://api-inference.huggingface.co/models/damo-vilab/text-to-video-ms-1.7b', {
                headers: {
                    'Authorization': `Bearer ${this.apiKey}`,
                    'Content-Type': 'application/json',
                },
                method: 'POST',
                body: JSON.stringify({
                    inputs: this.optimizePromptForImageToVideo(prompt),
                    parameters: {
                        num_frames: options.num_frames || 16,
                        fps: options.fps || 8,
                        width: options.width || 256,
                        height: options.height || 256
                    }
                })
            });

            if (!response.ok) {
                throw new Error(`Erreur API fallback: ${response.status}`);
            }

            const videoBuffer = Buffer.from(await response.arrayBuffer());
            
            const outputDir = path.dirname(outputPath);
            await fs.mkdir(outputDir, { recursive: true });

            await fs.writeFile(outputPath, videoBuffer);
            console.log(`‚úÖ Vid√©o Hugging Face g√©n√©r√©e avec mod√®le de fallback: ${outputPath}`);
            
            return {
                success: true,
                videoPath: outputPath,
                duration: options.duration || 5,
                provider: 'huggingface',
                model: 'damo-vilab/text-to-video-ms-1.7b',
                fileSize: videoBuffer.length
            };

        } catch (error) {
            console.error('‚ùå Erreur mod√®le de fallback:', error.message);
            throw error;
        }
    }

    optimizePromptForImageToVideo(prompt) {
        // Optimiser le prompt sp√©cifiquement pour image-to-video
        let optimized = prompt
            .replace(/['"]/g, '') // Supprimer les guillemets
            .replace(/\s+/g, ' ') // Normaliser les espaces
            .trim();

        // Ajouter des am√©liorations pour l'image-to-video
        const improvements = [
            'smooth movement',
            'natural motion',
            'fluid animation',
            'realistic movement',
            'cinematic quality'
        ];

        // Ajouter les am√©liorations si pas d√©j√† pr√©sentes
        improvements.forEach(improvement => {
            if (!optimized.toLowerCase().includes(improvement.toLowerCase())) {
                optimized += `, ${improvement}`;
            }
        });

        // Limiter la longueur pour le mod√®le
        if (optimized.length > 200) {
            optimized = optimized.substring(0, 197) + '...';
        }

        console.log(`üéØ Prompt optimis√© pour image-to-video: "${optimized}"`);
        return optimized;
    }

    // M√©thodes RPG sp√©cifiques avec support d'image
    async generateCombatVideo(action, character, outputPath) {
        const prompt = `${character.name} in medieval fantasy combat, ${action}, epic battle scene, dynamic movement, armor and weapons, dramatic lighting, action sequence`;
        
        return await this.generateVideoFromText(prompt, outputPath, {
            duration: 4,
            characterImagePath: character.imagePath || null
        });
    }

    async generateCharacterActionVideo(action, character, location, outputPath) {
        const prompt = `${character.name} performing ${action} in ${location}, medieval fantasy setting, character in motion, atmospheric environment, cinematic camera angle`;
        
        return await this.generateVideoFromText(prompt, outputPath, {
            duration: 5,
            characterImagePath: character.imagePath || null
        });
    }

    async generateLocationVideo(location, character, outputPath) {
        const prompt = `Fantasy location: ${location}, ${character.name} exploring the area, epic landscape, atmospheric lighting, cinematic camera movement, medieval fantasy world`;
        
        return await this.generateVideoFromText(prompt, outputPath, {
            duration: 6,
            characterImagePath: character.imagePath || null
        });
    }

    async generateMagicSpellVideo(spellName, character, outputPath) {
        const prompt = `${character.name} casting ${spellName} magic spell, mystical energy effects, glowing magical aura, fantasy spellcasting, dynamic magical particles, epic scene`;
        
        return await this.generateVideoFromText(prompt, outputPath, {
            duration: 4,
            characterImagePath: character.imagePath || null
        });
    }

    // Nouvelle m√©thode pour g√©n√©rer une vid√©o avec une image personnalis√©e
    async generateVideoFromImage(imagePath, prompt, outputPath, options = {}) {
        try {
            console.log(`üé¨ G√©n√©ration vid√©o depuis image: ${imagePath}`);
            
            return await this.generateVideoFromText(prompt, outputPath, {
                ...options,
                characterImagePath: imagePath
            });
        } catch (error) {
            console.error('‚ùå Erreur g√©n√©ration vid√©o depuis image:', error);
            throw error;
        }
    }
}

module.exports = HuggingFaceClient;
